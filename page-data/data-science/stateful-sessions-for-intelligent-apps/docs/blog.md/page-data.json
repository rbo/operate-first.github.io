{"componentChunkName":"component---src-templates-markdown-js","path":"/data-science/stateful-sessions-for-intelligent-apps/docs/blog.md","result":{"data":{"site":{"siteMetadata":{"title":"Operate First"}},"markdownRemark":{"id":"7de10339-1d5e-573a-b814-c4400558bac0","html":"<p><em>Authors:</em> Gage Krumbach</p>\n<p><em>Date Created:</em> 30th April 2021</p>\n<p><em>Last Updated:</em> 3rd June 2021</p>\n<p><em>Tags:</em> api, stateful, state, kafka, openshift, sticky sessions, sentiment analysis, realtime, audio decoding</p>\n<h2 id=\"in-this-demo\" style=\"position:relative;\"><a href=\"#in-this-demo\" aria-label=\"in this demo permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>In this demo</h2>\n<p>We will look into solving an architectural problem in an end to end machine learning application.\nFirst we will walk through the sample problem and outline the solution. Then we will\nget the sample application running for you to try out. Also feel free to check out the talk [<a href=\"https://www.youtube.com/watch?v=F_n90IBrSaM\">1</a>] I did\nat DevConf [<a href=\"https://devconfcz2021.sched.com/event/gmNH\">2</a>] where I went into more\ndetail on the setup and troubleshooting of use cases like this.</p>\n<h2 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Introduction</h2>\n<p>This end to end demo tackles the problem of dealing with state in a realtime machine learning\napplication.</p>\n<h3 id=\"statefulness\" style=\"position:relative;\"><a href=\"#statefulness\" aria-label=\"statefulness permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Statefulness</h3>\n<p>In general, when an application is stateful, it utilizes previous interactions.\nFor example this could be a shopping cart on an e-commerce website. In a stateful API,\neach request builds off the last request where a single request can not be\ninterpreted alone. These types of APIs go against OpenShift/Kube’s default model of\nhaving “stateless microservices”. Therefore many of the benefits of OpenShift’s\nscale-out compute resources are no longer available.</p>\n<p>In some use cases, real time analysis is desired which creates numerous issues for your\narchitecture such as scheduling tasks and scaling up your model services. In this\ndemo we will look into a use case where multiple models need to be strung together\nfor real time analysis. We will also tackle the scaling issue for stateful APIs.</p>\n<h2 id=\"problem\" style=\"position:relative;\"><a href=\"#problem\" aria-label=\"problem permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Problem</h2>\n<p>Imagine you are a call center supervisor and need to manage 100+ phone lines. You\nare responsible for making sure the quality of the calls are positive. Right now\nyou are randomly joining calls and monitoring them individually but you would like\nto automate this process.</p>\n<h2 id=\"solution\" style=\"position:relative;\"><a href=\"#solution\" aria-label=\"solution permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Solution</h2>\n<p>We will build our app using OpenShift and Open Data Hub. We can deploy two model\nservices to solve our problem:</p>\n<ul class=\"pf-c-list\">\n<li>An audio decoding model - to convert to live phone calls to text.</li>\n<li>A sentiment analysis model - to extract relevant information from the text.</li>\n</ul>\n<p>We will also deploy a web app to display our model’s output in a readable\nformat.</p>\n<p><strong>Note</strong></p>\n<p>The audio decoding model is deployed using a stateful API. Because it is decoding audio live,\nit only gets chunks of audio every 1 second opposed to getting all the audio in one big file.\nTherefore, we must save the state / previous audio chunk in the API, otherwise the model loses all reference of\nthe previously decoded speech, resulting in poor model performance.</p>\n<h3 id=\"issues\" style=\"position:relative;\"><a href=\"#issues\" aria-label=\"issues permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Issues</h3>\n<ol class=\"pf-c-list\">\n<li>How do we string together all of our components (models, web app, phone lines)?</li>\n<li>How do we scale our audio decoder model (support many phone lines)?</li>\n</ol>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/operate-first.github.io/static/6a21abad2e8c46e4182c19c5bf636b54/eb2ef/arch-1.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 44.5945945945946%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB/ElEQVQoz02SW2/aUBCE/f9/QN9btY3yUKlKlDQpoEQJpWAb37AJxsSxsTG3YkzIpSkpXxcnqmJptDPHe3ZXs0fhzbde5Swim2LosIwlxg554jFtnTMWJL7OsNsi9prMQ5s86ki+U2LHZ6GFMplMCIKA6WzOOp9xd/2DRWiUxRYDjT8jjcejT6wOPmCf7WNX91CP33M3qMPEYDvS2WY6ZG2e4iaKbducnpzQNi3mWUweNHGvfNEOgd/lIWrynOis+nUehhoPsQozB6Y2T0NV0JJCLTaJ/ItaKK7rUq1WcTou0eCKyKximiYHh4eEfY+RecKsV8ex2uhqC0PXRP9g5laJPJW475AM5G5XY33deClYqXyn43qkNwEHH9+RZWNGgl+TFL/+RZrUcDsOn/f2MS2baa/BoPEV1zY4/Fbh6FQGsi3W4U8Uz/Oo1Wr/J5x0L2VCi0q1xrXviad1bkMVS2twXjvF0pusRG8SlczXGPYM4qs2Wb8tuTKhZVkcHx+h6W0Wk6T00HY6pfY9h/uwwd/MKP16TnfG74rpJd+IfxtZRAlp8Ch+K8vlkjRNyZcFd8Wc+5smRWSyThyKG51NqrEdG7JFweglbkcvEINFm8Iljk1+S1Pl7TvMZ2OWvXNug0vZ6kUZi/4lS/+Cwhfe28VXXuJV784lb+6d8Q9xZn9jwWMb9gAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"arch-1\"\n        title=\"Missing Connections\"\n        src=\"/operate-first.github.io/static/6a21abad2e8c46e4182c19c5bf636b54/fcda8/arch-1.png\"\n        srcset=\"/operate-first.github.io/static/6a21abad2e8c46e4182c19c5bf636b54/12f09/arch-1.png 148w,\n/operate-first.github.io/static/6a21abad2e8c46e4182c19c5bf636b54/e4a3f/arch-1.png 295w,\n/operate-first.github.io/static/6a21abad2e8c46e4182c19c5bf636b54/fcda8/arch-1.png 590w,\n/operate-first.github.io/static/6a21abad2e8c46e4182c19c5bf636b54/efc66/arch-1.png 885w,\n/operate-first.github.io/static/6a21abad2e8c46e4182c19c5bf636b54/c83ae/arch-1.png 1180w,\n/operate-first.github.io/static/6a21abad2e8c46e4182c19c5bf636b54/eb2ef/arch-1.png 1324w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\nFigure 1. architecture layout with missing connection between the elements of the app.</p>\n<h4 id=\"stringing-it-together\" style=\"position:relative;\"><a href=\"#stringing-it-together\" aria-label=\"stringing it together permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Stringing it together</h4>\n<p>What we want is something that will send data from our audio decoder model, to our\nsentiment analysis model, and then finally to our web app for visualization. We also\nwant to scale our models, so that they cumulatively can handle larger\nloads (more phone lines).</p>\n<p>We will use Kafka to accomplish this [<a href=\"https://kafka.apache.org/intro\">3</a>].\nKafka will stream the data from the outputs of our models to the inputs of the\nother models. We will also configure Kafka to auto commit messages. This means\nthat when we scale our model services to multiple instances, Kafka will distribute the processing load\nacross each instance while preventing reprocessing of already processed data. This is done\nby keeping all of our consumers (sentiment analysis model service instances) on the same group id.\nConsumers with the same group id will not reprocess already processed data.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/operate-first.github.io/static/27c384097270823028bc063f1fa36e5f/016a8/arch-2.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50.67567567567568%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAACM0lEQVQoz12SW2/aQBCF+f8/oa9RVfW1pA0kFIKJwWBjG3zD3LENAcLN3BJC4OuWpFLUkY5mVjt75szsJPjPzufzxe92MYtsknUuyayj09ZLBKbKwCjT1xURlxla1U/QGHllEp9J/vrz6XSJt+s5j9+/sPl5xcyroBTy+LKJkZbQbvLoKYlQdYg0V8AjqFiExj2JC8kHPts2XjD3C7wOReWazLerr7i2jee4eLbDKIwYfuBxOKLteAz0/LvCf3Y6vfGy33A87FlNIw6hClOTcb1I6iaN6zr4foMgCFjFK9brNXEcs9ltCXs9QSgULpdLqtUqkaiyXT3Rd8p0mw5dR+MlUDlGFQZaHk01qFsWjlDY6fYIhLJWu0Oz2aLV6WGb9XfC8XhMOp0WyTaTqEe/YVCQFeyazmlksGk/EGhZ1HyOUi6DnLnFLBbQZQmjKCH/vqUq4ppAaIqWp9Mp18mkaKWJZ5k8ZFN4Im56FquWzNKXLj4y75i595cCx7DC3M2x75V47hV5NNMcA4Vlq0RiMpmQydzhNXz67QaeWAezbuO7Fvt+RbStYaglCgWJoKGLEYgxDKvEosghqBB4GvWqQlOsTWDL74SpVApL/Fw8e6RjKZQVRSSVeA3KvEWaOBf5cf2LrquzamSJmxJbofR1oGBpRW7vMkiSRLdWIHE8HlkuF7wcDjzv1kzaBrO+zVO3RhzUWQn4dRXHEGp8MdPQYhNZbCObtbib9y0Wocd84DAWb/8A6TDKxyh+98IAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"arch-2\"\n        title=\"Kafka Connections\"\n        src=\"/operate-first.github.io/static/27c384097270823028bc063f1fa36e5f/fcda8/arch-2.png\"\n        srcset=\"/operate-first.github.io/static/27c384097270823028bc063f1fa36e5f/12f09/arch-2.png 148w,\n/operate-first.github.io/static/27c384097270823028bc063f1fa36e5f/e4a3f/arch-2.png 295w,\n/operate-first.github.io/static/27c384097270823028bc063f1fa36e5f/fcda8/arch-2.png 590w,\n/operate-first.github.io/static/27c384097270823028bc063f1fa36e5f/efc66/arch-2.png 885w,\n/operate-first.github.io/static/27c384097270823028bc063f1fa36e5f/c83ae/arch-2.png 1180w,\n/operate-first.github.io/static/27c384097270823028bc063f1fa36e5f/016a8/arch-2.png 1576w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\nFigure 2. architecture layout with Kafka introduced and connected</p>\n<h4 id=\"scaling-the-audio-decoder\" style=\"position:relative;\"><a href=\"#scaling-the-audio-decoder\" aria-label=\"scaling the audio decoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Scaling the audio decoder</h4>\n<p>The last issue in our architecture is how we will scale our stateful API (audio decoder).\nBecause the API needs to store the state of previous calls, we can not use the traditional\nscaling features of a REST API. Those strategies might use a round-robin load balancing\ntechnique which does not guarantee that clients will hit the same endpoint on every\ncall to the API. To fix this, we can utilize OpenShift sticky sessions [<a href=\"https://docs.openshift.com/container-platform/4.7/networking/routes/route-configuration.html#nw-using-cookies-keep-route-statefulness_route-configuration\">4</a>]. This feature tells the\ningress controller to attach a cookie to a api response, where a cookie is linked\nto an endpoint. Meaning a client will always go to the same endpoint as long as it\nstores the cookie and uses it in the next API request.</p>\n<p>Now we can safely scale the API as if it was a REST API.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/operate-first.github.io/static/440c879f3e9b237937b5888ad8ce3db7/76435/arch-3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 38.513513513513516%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAABl0lEQVQoz2VRy07CQBTlz9SoxET3PlJ0oXvjn6BRN6gLtkaNDxYGCC8TqFoaSlMKCZUWCI8A4U0sjyN3mhojN3OSmTt37px7jmM2m+Fv2OfpdLqQt2GfM5kMeP4dqaQERVYhp2U46NI0TQwGA7RaLSiKgng8jlwuh36/j+FwiPF4jP9BOb1gwB96hffJA9/bPZLSp9Ww1+sxUNNisQhBEJDNZtFut9FoNFAul1lju8aOLyOPE68LBx4ntt1LeI7cwVEqlVAoFNgjAo1CjwzD+M1RDYH2VGuOTXyPTHyk49hxr4A7dYK7WMNL5AEOURQRDocRCASgqiomkwkbNRqNIpFIIBgMIhaLMRl8Pt9cM96Soj+ClBNxeLWJo5stuC7XrYb0q6ZpDMSCGnY6HcawUqkw2Owop+s65tawkRVNwt7pKrizdexeLOMxdGtp2O122ZikE2lI7pEppGGz2US9Xmd3xIzqmNPzJWVF7J9vzNk5cXzN4Y2PLrqcSqXg9/shy/LvJ4suWwxr9SqEDA9BTUDT86hWavgBbR86wyXgxT8AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"arch-3\"\n        title=\"Ingress Controller\"\n        src=\"/operate-first.github.io/static/440c879f3e9b237937b5888ad8ce3db7/fcda8/arch-3.png\"\n        srcset=\"/operate-first.github.io/static/440c879f3e9b237937b5888ad8ce3db7/12f09/arch-3.png 148w,\n/operate-first.github.io/static/440c879f3e9b237937b5888ad8ce3db7/e4a3f/arch-3.png 295w,\n/operate-first.github.io/static/440c879f3e9b237937b5888ad8ce3db7/fcda8/arch-3.png 590w,\n/operate-first.github.io/static/440c879f3e9b237937b5888ad8ce3db7/efc66/arch-3.png 885w,\n/operate-first.github.io/static/440c879f3e9b237937b5888ad8ce3db7/c83ae/arch-3.png 1180w,\n/operate-first.github.io/static/440c879f3e9b237937b5888ad8ce3db7/76435/arch-3.png 1742w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span>\nFigure 3. ingress controller using cookies to maintain statefulness.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>This technique for preserving state in an API is not the only solution nor is it\na complete solution. However this technique provides a quick and relatively lightweight\nway of making the API scalable. Because this type of architecture follows a\npipe and filter approach to data flow, it is easy to update single components such as\nthe model service. A data scientists can directly play around with the ML notebook while it\nis functioning inside the architecture as a whole. That alone is a powerful development tool.\nYou will have a chance to see that in action below.</p>\n<h2 id=\"project-materials\" style=\"position:relative;\"><a href=\"#project-materials\" aria-label=\"project materials permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Project Materials</h2>\n<h3 id=\"launch-the-sentiment-analysis-model-service\" style=\"position:relative;\"><a href=\"#launch-the-sentiment-analysis-model-service\" aria-label=\"launch the sentiment analysis model service permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Launch the sentiment analysis model service</h3>\n<p>In this demo there is a default sentiment analysis model service that is always\nrunning. You will be contributing to the computations in your Jupyter notebook\nin parallel with the default model service.</p>\n<ol class=\"pf-c-list\">\n<li>Visit <a href=\"https://odh.operate-first.cloud\">https://odh.operate-first.cloud</a></li>\n<li>Launch JupyterHub</li>\n<li>Login with moc-sso and then login your google account</li>\n<li>In this Spawn screen, select <code class=\"language-text\">audio-decoder-demo:latest</code> (no need to change other settings)</li>\n<li>Once your server starts, go into the directory named <code class=\"language-text\">audio-decoder-demo-yyyy-mm-dd-hh-mm</code></li>\n<li>Run the notebook named <code class=\"language-text\">sentiment.ipynb</code> and follow instructions</li>\n</ol>\n<h3 id=\"see-the-results\" style=\"position:relative;\"><a href=\"#see-the-results\" aria-label=\"see the results permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>See the results</h3>\n<p>You can access the web app here: <a href=\"http://call-center-manage-client-fde-audio-decoder-demo.apps.zero.massopen.cloud/\">http://call-center-manage-client-fde-audio-decoder-demo.apps.zero.massopen.cloud/</a></p>\n<p>You can access the OpenShift namespace here: <a href=\"https://console-openshift-console.apps.zero.massopen.cloud/topology/ns/fde-audio-decoder-demo\">https://console-openshift-console.apps.zero.massopen.cloud/topology/ns/fde-audio-decoder-demo</a></p>\n<p>In the namespace under the <a href=\"https://console-openshift-console.apps.zero.massopen.cloud/dev-monitoring/ns/fde-audio-decoder-demo/?workloadName=audio-decoder&#x26;workloadType=deployment\">monitoring dashboard</a>, notice that the audio-decoder api\nis properly disturbing the load still.</p>\n<h3 id=\"how-to-contribute--provide-feedback\" style=\"position:relative;\"><a href=\"#how-to-contribute--provide-feedback\" aria-label=\"how to contribute  provide feedback permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>How to Contribute / Provide feedback</h3>\n<ul class=\"pf-c-list\">\n<li>\n<p>Github Repositories:</p>\n<ul class=\"pf-c-list\">\n<li><a href=\"https://github.com/Gkrumbach07/audio-decoder-demo\">https://github.com/Gkrumbach07/audio-decoder-demo</a> (notebook)</li>\n<li><a href=\"https://github.com/Gkrumbach07/docker-py-kaldi-asr\">https://github.com/Gkrumbach07/docker-py-kaldi-asr</a> (api &#x26; simulator)</li>\n<li><a href=\"https://github.com/Gkrumbach07/call_center_manage\">https://github.com/Gkrumbach07/call_center_manage</a> (web app)</li>\n</ul>\n</li>\n<li>You can open up a PR on the Git Repository highlighting the feature or issue, and we will address it.</li>\n<li>You can also reach out to gkrumbac@redhat.com for any questions.</li>\n</ul>\n<h2 id=\"references\" style=\"position:relative;\"><a href=\"#references\" aria-label=\"references permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>References</h2>\n<p>[1] <a href=\"https://www.youtube.com/watch?v=F_n90IBrSaM\">https://www.youtube.com/watch?v=F_n90IBrSaM</a></p>\n<p>[2] <a href=\"https://devconfcz2021.sched.com/event/gmNH\">https://devconfcz2021.sched.com/event/gmNH</a></p>\n<p>[3] <a href=\"https://kafka.apache.org/intro\">https://kafka.apache.org/intro</a></p>\n<p>[4] <a href=\"https://docs.openshift.com/container-platform/4.7/networking/routes/route-configuration.html#nw-using-cookies-keep-route-statefulness_route-configuration\">https://docs.openshift.com/container-platform/4.7/networking/routes/route-configuration.html#nw-using-cookies-keep-route-statefulness_route-configuration</a></p>","fields":{"srcLink":"https://github.com/Gkrumbach07/audio-decoder-demo/blob/master/docs/blog.md"},"frontmatter":{"title":"Stateful Sessions for Intelligent Apps","description":"Stateful Sessions for Intelligent Apps","extraClasses":null}}},"pageContext":{"id":"7de10339-1d5e-573a-b814-c4400558bac0"}},"staticQueryHashes":["117426894","3000541721","3606484676","533861647"]}