{"componentChunkName":"component---src-templates-markdown-js","path":"/data-science/pet-image-detection/README.md","result":{"data":{"site":{"siteMetadata":{"title":"Operate First"}},"markdownRemark":{"id":"705a725c-d038-5458-8e57-0e4d3a655cff","html":"<h1 id=\"image-detection-demo\" style=\"position:relative;\"><a href=\"#image-detection-demo\" aria-label=\"image detection demo permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Image Detection Demo</h1>\n<p><em>A brief introduction to model serving with Seldon using the InceptionV3 image recognition model.</em></p>\n<p>After a data scientist has created and trained a model, the next step is putting the model into production. Model serving deploys machine learning models as microservices that can interact easily with other pieces of a larger intelligent application. </p>\n<p>This repo utilizes the <a href=\"https://keras.io/api/applications/inceptionv3/\">InceptionV3</a> image recognition model alongside <a href=\"https://github.com/SeldonIO/seldon-core\">Seldon Core</a> in order to create a simple model serving demo. The notebook <code class=\"language-text\">model-explainability.ipynb</code> initiates a gateway endpoint between the Jupyter Notebook and Seldon deployment, allowing users to send data to the model service and receive predictions. A local explainability algorithm is also implemented to better understand how the model is making its predictions. </p>\n<p><strong><a href=\"docs/get-started.md\">Get Started</a></strong></p>\n<p><strong><a href=\"docs/content.md\">Project Content</a></strong></p>\n<p><strong><a href=\"docs/how-to-contribute.md\">How to Contribute</a></strong></p>\n<h2 id=\"contact\" style=\"position:relative;\"><a href=\"#contact\" aria-label=\"contact permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Contact</h2>\n<p>This project is maintained by the AIOps teams in the AI Center of Excellence within the Office of the CTO at Red Hat. For more information, reach out to us at aicoe-aiops@redhat.com.</p>","fields":{"srcLink":"https://github.com/aicoe-aiops/pet-image-detection/blob/master/README.md"},"frontmatter":{"title":"","description":null,"extraClasses":null}}},"pageContext":{"id":"705a725c-d038-5458-8e57-0e4d3a655cff"}},"staticQueryHashes":["117426894","3000541721","3606484676","533861647"]}